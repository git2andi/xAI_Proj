\section{Introduction}\label{intro}

The core of this project was to understand the key principles of deep learning and to apply them in a practical environment. This was achieved through two challenges. The first was to classify the digits 0~-~9 in the MNIST dataset, while the second challenge was to classify nine different tissue patterns in the PathMNIST dataset. A crucial first step in developing an effective classification model was to thoroughly investigate and understand the dataset at hand. Therefore, our investigation began with an introduction to the well-known datasets MNIST \citep{deng2012mnist} and MedMNIST \citep{medmnistv1}, which served as building blocks for our study.

The project was structured to take account of the different characteristics of the individual datasets. We started with MNIST, which was chosen due to its wide distribution and the numerous tutorials available, which simplified our entry into the field of deep learning. With this dataset, we took on the challenge of developing a rudimentary Convolutional Neural Network (SimpleCNN) that was intentionally designed with a limited number of layers. The initial aim of this challenge was not to achieve peak performance, but rather to gain practical experience and understand the basics of the architecture of neural networks and their ability to distinguish between different digits.

As our knowledge increased, we shifted our focus to the more challenging MedMNIST dataset, focusing particularly on the PathMNIST subset. This phase formed the core of our project, in which we focused intensively on experimenting with different pre-trained models. Our investigations extended to testing a wide range of hyperparameters as well as implementing different strategies for data preprocessing and augmentation. 

The report is structured as follows: First, the datasets used~-~MNIST and MedMNIST~-~are briefly introduced. We then review some theoretical foundations that are important for understanding the methods used in each challenge, such as the dropout layer or ReLU.\@ This is followed by an explanation of different architectures of deep learning models, starting from our SimpleCNN to more advanced models such as AlexNet, ResNet and Xception. We then present the results obtained with each model for the respective challenges. In the discussion that follows, we critically evaluate our results for each model. Finally, we briefly reflect on the lessons we have learned from the project.

\input{chapter/data.tex}
