\section{Introduction}\label{intro}


The emergence of deep learning has led to unprecedented advances in various fields, including medical image analysis. This project seeks to explore the fundamental principles of deep learning and to leverage its potential in a practical setting. Our investigation is divided into two parts: First, we focus on the classification of handwritten digits using the MNIST dataset \citep{mnist}, followed by a more complicated challenge of classifying nine different tissue patterns within the PathMNIST dataset \citep{kather2018, kather2019}, a subset of MedMNIST \citep{medmnistv1}. These tasks not only serve as a basis for understanding the mechanisms of deep learning, but also highlight the impact of the application of neural networks in medical diagnostics, emphasizing the relevance of our research.

At the centre of our project is the hypothesis that specific adaptations and refinements of deep learning techniques can significantly improve model performance on both simple and complex classification tasks. First, using the MNIST dataset, we hypothesised that fine-tuning hyperparameters such as batch size, learning rate and number of epochs could directly influence model accuracy and training efficiency. This hypothesis was extended to the more challenging PathMNIST dataset, where we hypothesised that the application of more sophisticated architectures and strategies~-~including pre-trained models, diverse optimisers and advanced data balancing, pre-processing and augmentation techniques~-~would prove crucial in managing the complexity of the dataset and achieving high classification accuracy.

This report is structured by first briefly introducing the generic Deep Learning Pipeline as outlined by \citep{alzubaidi2021review}. Following this, some theoretical foundations that are crucial for understanding the methods used, data normalization, balancing and augmentation, batch normalization. Next, we explain the architectures of different deep learning models that were investigated in the project, from our initial SimpleCNN to more complex pretrained models such as AlexNet \citep{AlexNetoriginal}, ResNet \citep{he2015deep} and Xception \citep{chollet2017xception}. Subsequently, a brief overview of the used datasets MNIST and MedMNIST is given, which form the basis for a deeper investigation. We then present the results obtained with each architecture, addressing the specific challenges. The discussion section provides a critical evaluation of our results and leads to a reflective conclusion about the lessons learned and the potential impact of our research on medical image analysis.
